name: Design Token Validation

on:
  pull_request:
    paths:
      - 'packages/*/json/*.json'
      - 'packages/*/css/*.css'
    types: [opened, synchronize, reopened]

jobs:
  validate-tokens:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install pnpm
        uses: pnpm/action-setup@v4
        with:
          version: 8

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'pnpm'

      - name: Install dependencies
        run: pnpm install

      - name: Validate JSON Syntax
        run: |
          echo "ðŸ” Validating JSON file syntax..."

          INVALID_FILES=()

          find packages -name "*.json" -type f | while read file; do
            echo "Checking: $file"
            if ! pnpm node -e "
              try {
                JSON.parse(require('fs').readFileSync('$file', 'utf8'));
                console.log('âœ… Valid:', '$file');
              } catch (error) {
                console.error('âŒ Invalid:', '$file', error.message);
                process.exit(1);
              }
            "; then
              INVALID_FILES+=("$file")
            fi
          done

          if [ ${#INVALID_FILES[@]} -gt 0 ]; then
            echo "âŒ Files with JSON syntax errors:"
            printf '%s\n' "${INVALID_FILES[@]}"
            exit 1
          fi

          echo "âœ… All JSON files are valid."

      - name: Validate Token Structure
        run: |
          echo "ðŸ—ï¸ Validating token structure..."

          pnpm node -e "
            const fs = require('fs');
            const path = require('path');

            const requiredStructure = {
              'core-tokens': ['color-primitive', 'spacing-primitive', 'radius-primitive', 'typography-primitive'],
              'web-tokens': ['color-semantic-lg-brand', 'color-semantic-mobile', 'color-semantic-mono-black', 'color-semantic-mono-white', 'color-semantic-web'],
              'webos-tokens': ['color-semantic-light', 'color-semantic-dark', 'radius-semantic'],
              'mobile-tokens': ['color-semantic-lg-brand', 'color-semantic-mobile', 'color-semantic-mono-black', 'color-semantic-mono-white', 'color-semantic-web']
            };

            let errors = [];

            for (const [packageName, requiredFiles] of Object.entries(requiredStructure)) {
              const packagePath = path.join('packages', packageName, 'json');

              if (!fs.existsSync(packagePath)) {
                errors.push(\`Package directory missing: \${packagePath}\`);
                continue;
              }

              for (const requiredFile of requiredFiles) {
                const filePath = path.join(packagePath, \`\${requiredFile}.json\`);
                if (!fs.existsSync(filePath)) {
                  errors.push(\`Required file missing: \${filePath}\`);
                }
              }
            }

            if (errors.length > 0) {
              console.error('âŒ Structure validation failed:');
              errors.forEach(error => console.error('  -', error));
              process.exit(1);
            }

            console.log('âœ… Token structure is correct.');
          "

      - name: Validate Token References
        run: |
          echo "ðŸ”— Validating token references..."

          pnpm node -e "
            const fs = require('fs');
            const path = require('path');

            function loadAllTokens() {
              const tokens = {};
              const packagesDir = 'packages';

              const packages = fs.readdirSync(packagesDir);

              for (const pkg of packages) {
                const jsonDir = path.join(packagesDir, pkg, 'json');
                if (fs.existsSync(jsonDir)) {
                  tokens[pkg] = {};
                  const jsonFiles = fs.readdirSync(jsonDir);

                  for (const file of jsonFiles.filter(f => f.endsWith('.json'))) {
                    const filePath = path.join(jsonDir, file);
                    const content = JSON.parse(fs.readFileSync(filePath, 'utf8'));
                    const baseName = path.basename(file, '.json');
                    tokens[pkg][baseName] = content;
                  }
                }
              }

              return tokens;
            }

            function findReferences(obj, refs = []) {
              if (typeof obj === 'object' && obj !== null) {
                if (obj.\$ref) {
                  refs.push(obj.\$ref);
                } else {
                  Object.values(obj).forEach(value => findReferences(value, refs));
                }
              }
              return refs;
            }

            function validateReference(ref, allTokens) {
              // \$ref format: 'core-tokens/json/color-primitive.json#/primitive/color/black'
              const [filePath, jsonPath] = ref.split('#');
              const pathParts = filePath.split('/');
              const packageName = pathParts[0];
              const fileName = pathParts[2].replace('.json', '');

              if (!allTokens[packageName] || !allTokens[packageName][fileName]) {
                return false;
              }

              const pathSegments = jsonPath.split('/').filter(s => s);
              let current = allTokens[packageName][fileName];

              for (const segment of pathSegments) {
                if (current && typeof current === 'object') {
                  current = current[segment];
                } else {
                  return false;
                }
              }

              return current !== undefined;
            }

            const allTokens = loadAllTokens();
            let invalidRefs = [];

            for (const [packageName, files] of Object.entries(allTokens)) {
              for (const [fileName, content] of Object.entries(files)) {
                const refs = findReferences(content);

                for (const ref of refs) {
                  if (!validateReference(ref, allTokens)) {
                    invalidRefs.push({
                      file: \`\${packageName}/\${fileName}.json\`,
                      reference: ref
                    });
                  }
                }
              }
            }

            if (invalidRefs.length > 0) {
              console.error('âŒ Invalid token references found:');
              invalidRefs.forEach(invalid => {
                console.error(\`  - \${invalid.file}: \${invalid.reference}\`);
              });
              process.exit(1);
            }

            console.log('âœ… All token references are valid.');
          "

      - name: Validate CSS Output
        run: |
          echo "ðŸŽ¨ Validating CSS output..."

          find packages -name "*.css" -type f | while read file; do
            echo "Checking: $file"

            # Check if CSS file has :root selector
            if ! grep -q ":root" "$file"; then
              echo "âš ï¸ CSS file missing :root selector: $file"
            fi

            # Check CSS variable format (should start with --), ignore :root, comments, and blank lines
            if grep ":" "$file" | grep -v "^\s*--" | grep -v "^\s*\/\*" | grep -v "^\s*\*" | grep -v "^\s*:root" | grep -v "^\s*$" | grep -q .; then
              echo "âš ï¸ Non-CSS variable properties found: $file"
            fi
          done

          echo "âœ… CSS output validation completed"

      - name: Check Package Versions
        run: |
          echo "ðŸ“¦ Validating package version consistency..."

          pnpm node -e "
            const fs = require('fs');
            const path = require('path');

            const mainPackage = JSON.parse(fs.readFileSync('package.json', 'utf8'));
            const mainVersion = mainPackage.version;

            const packages = ['core-tokens', 'web-tokens', 'webos-tokens', 'mobile-tokens'];
            let versionMismatches = [];

            for (const pkg of packages) {
              const pkgPath = path.join('packages', pkg, 'package.json');
              if (fs.existsSync(pkgPath)) {
                const pkgContent = JSON.parse(fs.readFileSync(pkgPath, 'utf8'));
                if (pkgContent.version !== mainVersion) {
                  versionMismatches.push(\`\${pkg}: \${pkgContent.version} (expected: \${mainVersion})\`);
                }
              }
            }

            if (versionMismatches.length > 0) {
              console.error('âŒ Version mismatches:');
              versionMismatches.forEach(mismatch => console.error('  -', mismatch));
              process.exit(1);
            }

            console.log('âœ… All package versions match.');
          "

      - name: Generate Validation Report
        if: always()
        run: |
          echo "ðŸ“‹ Generating validation report..."

          REPORT_FILE="validation-report.md"

          cat > $REPORT_FILE << EOF
          # ðŸŽ¨ Design Tokens Validation Report

          **Validation Time**: $(date)
          **Branch**: ${{ github.ref_name }}
          **Commit**: ${{ github.sha }}

          ## ðŸ“Š Validation Results

          - âœ… JSON syntax validation
          - âœ… Token structure validation
          - âœ… Token reference validation
          - âœ… CSS output validation
          - âœ… Package version validation

          ## ðŸ“ Checked Files

          EOF

          echo "### JSON Files" >> $REPORT_FILE
          find packages -name "*.json" -type f | while read file; do
            echo "- \`$file\`" >> $REPORT_FILE
          done

          echo "" >> $REPORT_FILE
          echo "### CSS Files" >> $REPORT_FILE
          find packages -name "*.css" -type f | while read file; do
            echo "- \`$file\`" >> $REPORT_FILE
          done

          echo "" >> $REPORT_FILE
          echo "---" >> $REPORT_FILE
          echo "ðŸ¤– Auto-generated report." >> $REPORT_FILE

          cat $REPORT_FILE

      - name: Upload Validation Report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: validation-report
          path: validation-report.md
